{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5eaa365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import  KafkaProducer\n",
    "import sys, os, json\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_json, struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b6258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728546f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = 'quickstart-events4'\n",
    "bootstrap_server=\"localhost:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9cacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17722f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adee7bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using packages ['org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0', 'org.apache.kafka:kafka-clients:3.5.1']\n"
     ]
    }
   ],
   "source": [
    "scala_version = '2.12'  # TODO: Ensure this is correct\n",
    "spark_version = '3.3.0'\n",
    "\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.5.1'\n",
    "]\n",
    "\n",
    "args = os.environ.get('PYSPARK_SUBMIT_ARGS', '')\n",
    "if not args:\n",
    "    args = f'--packages {\",\".join(packages)}'\n",
    "    print('Using packages', packages)\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = f'{args} pyspark-shell'\n",
    "else:\n",
    "    print(f'Found existing args: {args}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ba2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Java home\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk1.8.0_251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65c89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"ETLPipeline\") \\\n",
    "    .setMaster(\"local\") \\\n",
    "    .set(\"spark.driver.extraClassPath\",\"c:/pyspark/*\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "etl = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f333a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid=\"chaithanya\"\n",
    "pwd=\"12345678\"\n",
    "\n",
    "#sql db details\n",
    "server = \"localhost\"\n",
    "src_db = \"prac\"\n",
    "src_driver = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c257b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_url = f\"jdbc:sqlserver://{server}:1433;databaseName={src_db};user={uid};password={pwd};\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28adf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"select emp_id,emp_name,salary,manager_id from prac.dbo.emp_manager\"\"\"\n",
    "table=\"emp_manager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490c2d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+----------+\n",
      "|emp_id|emp_name|salary|manager_id|\n",
      "+------+--------+------+----------+\n",
      "|     1|   Ankit| 10000|         4|\n",
      "|     2|   Mohit| 15000|         5|\n",
      "|     3|   Vikas| 10000|         4|\n",
      "|     4|   Rohit|  5000|         2|\n",
      "|     5|   Mudit| 12000|         6|\n",
      "|     6|    Agam| 12000|         2|\n",
      "|     7|  Sanjay|  9000|         2|\n",
      "|     8|  Ashish|  5000|         2|\n",
      "|     9|  likhit|  1600|         4|\n",
      "+------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs=etl.read. \\\n",
    "    format(\"jdbc\"). \\\n",
    "    options(driver=src_driver, user=uid, password=pwd, url=src_url,query=query). \\\n",
    "    load()\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817bc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+----------+\n",
      "|emp_id|emp_name|salary|manager_id|\n",
      "+------+--------+------+----------+\n",
      "|     1|   Ankit| 10000|         4|\n",
      "|     2|   Mohit| 15000|         5|\n",
      "|     3|   Vikas| 10000|         4|\n",
      "|     4|   Rohit|  5000|         2|\n",
      "|     5|   Mudit| 12000|         6|\n",
      "|     6|    Agam| 12000|         2|\n",
      "|     7|  Sanjay|  9000|         2|\n",
      "|     8|  Ashish|  5000|         2|\n",
      "|     9|  likhit|  1600|         4|\n",
      "+------+--------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''kafka_df = dfs.selectExpr(\"CAST(emp_id AS STRING) AS key\", \"to_json(struct(*)) AS value\")\n",
    "kafka_df.show()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf6af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''kafka_df \\\n",
    "    .write \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_server) \\\n",
    "    .option(\"topic\", topic_name) \\\n",
    "    .save()\n",
    "print(\"Data written to Kafka topic 'Start'\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4017aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbc237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_kafka(dfs, key_column):\n",
    "    kafka_df = dfs.selectExpr(f\"CAST({key_column} AS STRING) AS key\", f\"to_json(struct(*)) AS value\").collect()\n",
    "    return kafka_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b9be87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(key='1', value='{\"emp_id\":1,\"emp_name\":\"Ankit\",\"salary\":10000,\"manager_id\":4}'), Row(key='2', value='{\"emp_id\":2,\"emp_name\":\"Mohit\",\"salary\":15000,\"manager_id\":5}'), Row(key='3', value='{\"emp_id\":3,\"emp_name\":\"Vikas\",\"salary\":10000,\"manager_id\":4}'), Row(key='4', value='{\"emp_id\":4,\"emp_name\":\"Rohit\",\"salary\":5000,\"manager_id\":2}'), Row(key='5', value='{\"emp_id\":5,\"emp_name\":\"Mudit\",\"salary\":12000,\"manager_id\":6}'), Row(key='6', value='{\"emp_id\":6,\"emp_name\":\"Agam\",\"salary\":12000,\"manager_id\":2}'), Row(key='7', value='{\"emp_id\":7,\"emp_name\":\"Sanjay\",\"salary\":9000,\"manager_id\":2}'), Row(key='8', value='{\"emp_id\":8,\"emp_name\":\"Ashish\",\"salary\":5000,\"manager_id\":2}'), Row(key='9', value='{\"emp_id\":9,\"emp_name\":\"likhit\",\"salary\":1600,\"manager_id\":4}')]\n"
     ]
    }
   ],
   "source": [
    "a = transform_data_for_kafka(dfs,'emp_id')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ecbafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        producer_instance.produce(topic_name, key=key, value=value)\n",
    "        producer_instance.flush()\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message:')\n",
    "        print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2378293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_to_kafka(dfs, kafka_bootstrap_servers, topic, key_column):\n",
    "    producer_config = {\n",
    "        'bootstrap.servers': kafka_bootstrap_servers,\n",
    "        'client.id': 'kafka-producer'\n",
    "    }\n",
    "\n",
    "    producer = Producer(producer_config)\n",
    "\n",
    "    kafka_df = transform_data_for_kafka(dfs, key_column)\n",
    "\n",
    "    for row in kafka_df:\n",
    "        key = row.key\n",
    "        value = row.value\n",
    "        publish_message(producer, topic, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57c7f0d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "publish_to_kafka(dfs, \"localhost:9092\", 'quickstart-events4','emp_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff13e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
